{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a new model\n",
    "\n",
    "In this notebook we will learn how to train a new model for axon & myelin segmentation. It covers the following scenario:\n",
    "\n",
    "* Train a model from scratch by defining the parameters of the network\n",
    "* Make inference using the trained model\n",
    "\n",
    "**Important:** If you have access to a GPU card, we strongly recommend you use it. By default, AxonDeepSeg will only use the CPU. To install the GPU compatible version of AxonDeepSeg, refer to the documentation: https://axondeepseg.readthedocs.io/en/latest/documentation.html#gpu-compatible-installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util import Retry\n",
    "\n",
    "# Scientific package imports\n",
    "import imageio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utils import\n",
    "from shutil import copy\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import cgi\n",
    "import tempfile\n",
    "\n",
    "# AxonDeepSeg imports\n",
    "try:\n",
    "    from AxonDeepSeg.ads_utils import download_data\n",
    "except ModuleNotFoundError:\n",
    "    # Change cwd to project main folder \n",
    "    os.chdir(\"..\")\n",
    "    try :\n",
    "        from AxonDeepSeg.ads_utils import download_data\n",
    "    except:\n",
    "        raise\n",
    "except:\n",
    "    raise\n",
    "# If no exceptions were raised import all folders        \n",
    "from AxonDeepSeg.config_tools import validate_config\n",
    "from AxonDeepSeg.train_network import train_model\n",
    "from AxonDeepSeg.apply_model import axon_segmentation\n",
    "import AxonDeepSeg.ads_utils as ads \n",
    "from config import axonmyelin_suffix\n",
    "\n",
    "# reset the tensorflow graph for new training\n",
    "tf.reset_default_graph()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Download example data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, please make sure you have split, patched, and organized your data in the correct way by running the [guide_dataset_building.ipynb](guide_dataset_building.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train a new model\n",
    "#### 1.1. Define the name and path of the training set\n",
    "\n",
    "Here we assume that the training data folder has already been created by following the guidelines detailed in [guide_dataset_building.ipynb](https://github.com/neuropoly/axondeepseg/blob/master/notebooks/guide_dataset_building.ipynb).\n",
    "\n",
    "The expected structure of the training data folder is the following:\n",
    "\n",
    "~~~\n",
    "data\n",
    " └── Train\n",
    "      └── image_0.png\n",
    "      └── mask_0.png\n",
    "      └── image_1.png\n",
    "      └── mask_1.png\n",
    "          ...\n",
    " └── Validation\n",
    "      └── image_0.png\n",
    "      └── mask_0.png\n",
    "      └── image_1.png\n",
    "      └── mask_1.png\n",
    "          ...\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_training = Path(\"./training\")  #  folder containing training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Define the U-Net architecture and hyper-parameters\n",
    "\n",
    "Here we defined the network and training parameters (i.e. hyperparameters). We use a lighter network than the ones used in the original [AxonDeepSeg article](https://www.nature.com/articles/s41598-018-22181-4), because they require large GPU memory (>12GB). The network below runs on an NVIDIA TitanX in ~2h. Note that the architecture below might not produce satisfactory results on your data so you likely need to play around with the architecture and hyperparameters.\n",
    "\n",
    "**Important:** The pixel size is not defined at the training step. During inference however, the parameter `-t {SEM,TEM,OM}` sets the resampling resolution to 0.1µm or 0.01µm depending on the model (i.e., implying the pixel size of the training data should be around 0.1µm for SEM and OM, and 0.01µm for TEM). This is definitely a limitation of the current version of AxonDeepSeg, which we are planning to solve at some point (for more info, see [Issue #152](https://github.com/neuropoly/axondeepseg/issues/152)). \n",
    "\n",
    "**Note about data augmentation:**\n",
    "For each type of data augmentation, the order needs to be specified if you decide to apply more than one transformation sequentially. For instance, setting `da-0-shifting-activate` to `True` means that the shifting is the first transformation that will be applied to the sample(s) during training. The default ranges of transformations are:\n",
    "- **Shifing**: Random horizontal and vertical shifting between 0 and 10% of the patch size, sampled from a uniform distribution.\n",
    "- **Rotation**: Random rotation, angle between 5 and 89 degrees, sampled from a uniform distribution.\n",
    "- **Rescaling**: Random rescaling of a randomly sampled factor between 1/1.2 and 1.2.\n",
    "- **Flipping**: Random fipping: vertical fipping or horizontal fipping.\n",
    "- **Elastic deformation**: Random elastic deformation with uniformly sampled deformation coefficient α=[1–8] and fixed standard deviation σ=4.\n",
    "\n",
    "You can find more information about the range of transformations applied to the patches for each data augmentation technique in the file [data_augmentation.py](https://github.com/neuropoly/axondeepseg/blob/master/AxonDeepSeg/data_management/data_augmentation.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of network configuration for TEM data (small network trainable on a Titan X GPU card)\n",
    "config = {\n",
    "    \n",
    "# General parameters:    \n",
    "  \"n_classes\": 3,  # Number of classes. For this application, the number of classes should be set to **3** (i.e. axon pixel, myelin pixel, or background pixel).\n",
    "  \"thresholds\": [0, 0.2, 0.8],  # Thresholds for the 3-class classification problem. Do not modify.  \n",
    "  \"trainingset_patchsize\": 512,  # Patch size of the training set in pixels (note that the patches have the same size in both dimensions).  \n",
    "  \"trainingset\": \"TEM\",  # Name of the training set.\n",
    "  \"batch_size\": 8,  # Batch size, i.e. the number of training patches used in one iteration of the training. Note that a larger batch size will take more memory.\n",
    "  \"epochs\":300,\n",
    "  \"checkpoint_period\": 5, # Number of epoch after which the model checkpoint is saved.\n",
    "  \"checkpoint\": None, # Checkpoint to use to resume training. Option: \"loss\", \"accuracy\" or None.\n",
    "\n",
    "# Network architecture parameters:     \n",
    "  \"depth\": 4,  # Depth of the network (i.e. number of blocks of the U-net).\n",
    "  \"convolution_per_layer\": [2, 2, 2, 2],  # Number of convolution layers used at each block.\n",
    "  \"size_of_convolutions_per_layer\": [[5, 5], [3, 3], [3, 3], [3, 3]],  # Kernel size of each convolution layer of the network.\n",
    "  \"features_per_convolution\": [[[1, 16], [16, 16]], [[16, 32], [32, 32]], [[32, 64], [64, 64]], [[64, 128], [128, 128]]],  # Number of features of each convolution layer.\n",
    "  \"downsampling\": \"convolution\",  # Type of downsampling to use in the downsampling layers of the network. Option \"maxpooling\" for standard max pooling layer or option \"convolution\" for learned convolutional downsampling.\n",
    "  \"dropout\": 0.75,  # Dropout to use for the training. Note: In TensorFlow, the keep probability is used instead. For instance, setting this param. to 0.75 means that 75% of the neurons of the network will be kept (i.e. dropout of 25%).\n",
    "     \n",
    "# Learning rate parameters:    \n",
    "  \"learning_rate\": 0.01,  # Learning rate to use in the training.  \n",
    "  \"learning_rate_decay_activate\": True,  # Set to \"True\" to use a decay on the learning rate.  \n",
    "  \"learning_rate_decay_period\": 24000,  # Period of the learning rate decay, expressed in number of images (samples) seen.\n",
    "  \"learning_rate_decay_type\": \"polynomial\",  # Type of decay to use. An exponential decay will be used by default unless this param. is set to \"polynomial\" (to use a polynomial decay).\n",
    "  \"learning_rate_decay_rate\": 0.99,  # Rate of the decay to use for the exponential decay. This only applies when the user does not set the decay type to \"polynomial\".\n",
    "    \n",
    "# Batch normalization parameters:     \n",
    "  \"batch_norm_activate\": True,  # Set to \"True\" to use batch normalization during the training.\n",
    "  \"batch_norm_decay_decay_activate\": True,  # Set to \"True\" to activate an exponential decay for the batch normalization step of the training.  \n",
    "  \"batch_norm_decay_starting_decay\": 0.7,  # The starting decay value for the batch normalization. \n",
    "  \"batch_norm_decay_ending_decay\": 0.9,  # The ending decay value for the batch normalization.\n",
    "  \"batch_norm_decay_decay_period\": 16000,  # Period of the batch normalization decay, expressed in number of images (samples) seen.\n",
    "        \n",
    "# Weighted cost parameters:    \n",
    "  \"weighted_cost-activate\": True,  # Set to \"True\" to use weights based on the class in the cost function for the training.\n",
    "  \"weighted_cost-balanced_activate\": True,  # Set to \"True\" to use weights in the cost function to correct class imbalance. \n",
    "  \"weighted_cost-balanced_weights\": [1.1, 1, 1.3],  # Values of the weights for the class imbalance. Typically, larger weights are assigned to classes with less pixels to add more penalty in the cost function when there is a misclassification. Order of the classes in the weights list: background, myelin, axon.\n",
    "  \"weighted_cost-boundaries_sigma\": 2,  # Set to \"True\" to add weights to the boundaries (e.g. penalize more when misclassification happens in the axon-myelin interface).\n",
    "  \"weighted_cost-boundaries_activate\": False,  # Value to control the distribution of the boundary weights (if activated). \n",
    "    \n",
    "# Data augmentation parameters:\n",
    "  \"da-type\": \"all\",  # Type of data augmentation procedure. Option \"all\" applies all selected data augmentation transformations sequentially, while option \"random\" only applies one of the selected transformations (randomly) to the sample(s). List of available data augmentation transformations: 'random_rotation', 'noise_addition', 'elastic', 'shifting', 'rescaling' and 'flipping'. \n",
    "  \"da-0-shifting-activate\": True, \n",
    "  \"da-1-rescaling-activate\": False,\n",
    "  \"da-2-random_rotation-activate\": False,  \n",
    "  \"da-3-elastic-activate\": True, \n",
    "  \"da-4-flipping-activate\": True, \n",
    "  \"da-6-reflection_border-activate\": False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Define training path and save configuration parameters\n",
    "\n",
    "Here we define the path where the new model will be saved. It is useful to add date+time in path definition in case multiple training are launched (to avoid conflicts).\n",
    "\n",
    "The network configuration parameters defined at 1.2. are saved into a .json file in the model folder. This .json file keeps tract of the network and model parameters in a structured way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This training session's model will be saved in the folder: /home/groups/bzuchero/axondeepseg/models/TEM_2021-11-15_21-44-09\n"
     ]
    }
   ],
   "source": [
    "# Define path to where the trained model will be saved\n",
    "dir_name = Path(config[\"trainingset\"] + '_' + time.strftime(\"%Y-%m-%d\") + '_' + time.strftime(\"%H-%M-%S\"))\n",
    "path_model = \"../models\" / dir_name\n",
    "\n",
    "print(\"This training session's model will be saved in the folder: \" + str(path_model.resolve().absolute()))\n",
    "\n",
    "# Create directory\n",
    "if not os.path.exists(path_model):\n",
    "    os.makedirs(path_model)\n",
    "\n",
    "# Define file name of network configuration\n",
    "file_config = 'config_network.json'\n",
    "\n",
    "# Load/Write config file (depending if it already exists or not)\n",
    "fname_config = os.path.join(path_model, file_config)\n",
    "if os.path.exists(fname_config):\n",
    "    with open(fname_config, 'r') as fd:\n",
    "        config_network = json.loads(fd.read())\n",
    "else:\n",
    "    with open(fname_config, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    with open(fname_config, 'r') as fd:\n",
    "        config_network = json.loads(fd.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Launch the training procedure\n",
    "\n",
    "The training can be launched by calling the *'train_model'* function. After each epoch, the function will display the loss and accuracy of the model. The model checkpoints will be saved according to the \"checkpoint_period\" parameter in \"config\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 21:44:12.487517: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2021-11-15 21:44:12.492884: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2021-11-15 21:44:12.493157: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55b2485f27e0 executing computations on platform Host. Devices:\n",
      "2021-11-15 21:44:12.493285: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2021-11-15 21:44:12.702168: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55b248664bd0 executing computations on platform CUDA. Devices:\n",
      "2021-11-15 21:44:12.702194: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2021-11-15 21:44:12.702329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:40:00.0\n",
      "totalMemory: 31.75GiB freeMemory: 31.45GiB\n",
      "2021-11-15 21:44:12.702341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2021-11-15 21:44:12.703738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-15 21:44:12.703747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2021-11-15 21:44:12.703751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2021-11-15 21:44:12.703812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30593 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:40:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/1000\n",
      "73/73 [==============================] - 47s 645ms/step - loss: 0.4319 - acc: 0.5602 - dice_axon: 0.0513 - dice_myelin: 0.6419 - val_loss: 0.3458 - val_acc: 0.6556 - val_dice_axon: 0.0043 - val_dice_myelin: 0.7587\n",
      "Epoch 2/1000\n",
      "73/73 [==============================] - 39s 528ms/step - loss: 0.3988 - acc: 0.5786 - dice_axon: 0.0074 - dice_myelin: 0.6495 - val_loss: 0.3419 - val_acc: 0.6588 - val_dice_axon: 0.0015 - val_dice_myelin: 0.7649\n",
      "Epoch 3/1000\n",
      "73/73 [==============================] - 38s 521ms/step - loss: 0.4030 - acc: 0.5739 - dice_axon: 0.0038 - dice_myelin: 0.6259 - val_loss: 0.3859 - val_acc: 0.6144 - val_dice_axon: 4.6997e-04 - val_dice_myelin: 0.6700\n",
      "Epoch 4/1000\n",
      "73/73 [==============================] - 38s 518ms/step - loss: 0.3957 - acc: 0.5792 - dice_axon: 0.0025 - dice_myelin: 0.6127 - val_loss: 0.3518 - val_acc: 0.6485 - val_dice_axon: 3.9158e-04 - val_dice_myelin: 0.7670\n",
      "Epoch 5/1000\n",
      "73/73 [==============================] - 38s 516ms/step - loss: 0.3938 - acc: 0.5804 - dice_axon: 0.0019 - dice_myelin: 0.6202 - val_loss: 0.3531 - val_acc: 0.6472 - val_dice_axon: 4.5289e-04 - val_dice_myelin: 0.7914\n",
      "Epoch 6/1000\n",
      "73/73 [==============================] - 38s 521ms/step - loss: 0.3947 - acc: 0.5792 - dice_axon: 0.0014 - dice_myelin: 0.6098 - val_loss: 0.3349 - val_acc: 0.6654 - val_dice_axon: 3.5514e-04 - val_dice_myelin: 0.7728\n",
      "Epoch 7/1000\n",
      "73/73 [==============================] - 37s 511ms/step - loss: 0.3856 - acc: 0.5882 - dice_axon: 0.0011 - dice_myelin: 0.6138 - val_loss: 0.3498 - val_acc: 0.6503 - val_dice_axon: 3.8300e-04 - val_dice_myelin: 0.7377\n",
      "Epoch 8/1000\n",
      "73/73 [==============================] - 40s 550ms/step - loss: 0.3922 - acc: 0.5825 - dice_axon: 0.0010 - dice_myelin: 0.6196 - val_loss: 0.3471 - val_acc: 0.6530 - val_dice_axon: 1.6786e-04 - val_dice_myelin: 0.7626\n",
      "Epoch 9/1000\n",
      "73/73 [==============================] - 38s 522ms/step - loss: 0.4077 - acc: 0.5659 - dice_axon: 8.8497e-04 - dice_myelin: 0.6187 - val_loss: 0.3617 - val_acc: 0.6385 - val_dice_axon: 4.4558e-04 - val_dice_myelin: 0.7249\n",
      "Epoch 10/1000\n",
      "73/73 [==============================] - 39s 533ms/step - loss: 0.3952 - acc: 0.5775 - dice_axon: 8.3249e-04 - dice_myelin: 0.6158 - val_loss: 0.3503 - val_acc: 0.6499 - val_dice_axon: 3.1567e-04 - val_dice_myelin: 0.7703\n",
      "Epoch 11/1000\n",
      "73/73 [==============================] - 37s 505ms/step - loss: 0.3945 - acc: 0.5794 - dice_axon: 7.0318e-04 - dice_myelin: 0.6119 - val_loss: 0.3423 - val_acc: 0.6578 - val_dice_axon: 2.2319e-04 - val_dice_myelin: 0.7531\n",
      "Epoch 12/1000\n",
      "73/73 [==============================] - 38s 516ms/step - loss: 0.3855 - acc: 0.5864 - dice_axon: 6.5456e-04 - dice_myelin: 0.6017 - val_loss: 0.3485 - val_acc: 0.6516 - val_dice_axon: 1.0581e-04 - val_dice_myelin: 0.7665\n",
      "Epoch 13/1000\n",
      "73/73 [==============================] - 37s 513ms/step - loss: 0.4021 - acc: 0.5708 - dice_axon: 5.8666e-04 - dice_myelin: 0.6248 - val_loss: 0.3428 - val_acc: 0.6574 - val_dice_axon: 1.3338e-04 - val_dice_myelin: 0.7799\n",
      "Epoch 14/1000\n",
      "73/73 [==============================] - 37s 512ms/step - loss: 0.3918 - acc: 0.5811 - dice_axon: 5.2889e-04 - dice_myelin: 0.6130 - val_loss: 0.3373 - val_acc: 0.6628 - val_dice_axon: 1.6238e-04 - val_dice_myelin: 0.7767\n",
      "Epoch 15/1000\n",
      "73/73 [==============================] - 39s 529ms/step - loss: 0.3816 - acc: 0.5980 - dice_axon: 5.1436e-04 - dice_myelin: 0.6254 - val_loss: 0.3658 - val_acc: 0.6343 - val_dice_axon: 2.5127e-04 - val_dice_myelin: 0.7095\n",
      "Epoch 16/1000\n",
      "73/73 [==============================] - 38s 516ms/step - loss: 0.4005 - acc: 0.5777 - dice_axon: 4.6831e-04 - dice_myelin: 0.6218 - val_loss: 0.3460 - val_acc: 0.6541 - val_dice_axon: 1.8232e-04 - val_dice_myelin: 0.7586\n",
      "Epoch 17/1000\n",
      "73/73 [==============================] - 38s 523ms/step - loss: 0.3943 - acc: 0.5811 - dice_axon: 4.1643e-04 - dice_myelin: 0.6299 - val_loss: 0.3372 - val_acc: 0.6630 - val_dice_axon: 2.4177e-04 - val_dice_myelin: 0.7640\n",
      "Epoch 18/1000\n",
      "73/73 [==============================] - 37s 507ms/step - loss: 0.3825 - acc: 0.6024 - dice_axon: 4.4976e-04 - dice_myelin: 0.6195 - val_loss: 0.3374 - val_acc: 0.6627 - val_dice_axon: 1.7311e-04 - val_dice_myelin: 0.7639\n",
      "Epoch 19/1000\n",
      "73/73 [==============================] - 37s 502ms/step - loss: 0.4098 - acc: 0.5650 - dice_axon: 3.6244e-04 - dice_myelin: 0.6157 - val_loss: 0.3421 - val_acc: 0.6580 - val_dice_axon: 1.5168e-04 - val_dice_myelin: 0.7787\n",
      "Epoch 20/1000\n",
      "73/73 [==============================] - 38s 523ms/step - loss: 0.3870 - acc: 0.5857 - dice_axon: 3.5445e-04 - dice_myelin: 0.6196 - val_loss: 0.3375 - val_acc: 0.6626 - val_dice_axon: 1.1287e-04 - val_dice_myelin: 0.7813\n",
      "Epoch 21/1000\n",
      "73/73 [==============================] - 38s 525ms/step - loss: 0.3883 - acc: 0.5846 - dice_axon: 3.3767e-04 - dice_myelin: 0.6152 - val_loss: 0.3378 - val_acc: 0.6623 - val_dice_axon: 1.7297e-04 - val_dice_myelin: 0.7704\n",
      "Epoch 22/1000\n",
      "73/73 [==============================] - 38s 514ms/step - loss: 0.3923 - acc: 0.5811 - dice_axon: 3.3495e-04 - dice_myelin: 0.6331 - val_loss: 0.3521 - val_acc: 0.6480 - val_dice_axon: 1.4538e-04 - val_dice_myelin: 0.7926\n",
      "Epoch 23/1000\n",
      "73/73 [==============================] - 39s 535ms/step - loss: 0.3935 - acc: 0.5797 - dice_axon: 3.4764e-04 - dice_myelin: 0.6326 - val_loss: 0.3444 - val_acc: 0.6556 - val_dice_axon: 1.2195e-04 - val_dice_myelin: 0.7855\n",
      "Epoch 24/1000\n",
      "73/73 [==============================] - 38s 526ms/step - loss: 0.3940 - acc: 0.5771 - dice_axon: 3.1959e-04 - dice_myelin: 0.6113 - val_loss: 0.3685 - val_acc: 0.6315 - val_dice_axon: 1.7999e-04 - val_dice_myelin: 0.7414\n",
      "Epoch 25/1000\n",
      "73/73 [==============================] - 37s 510ms/step - loss: 0.3819 - acc: 0.5921 - dice_axon: 2.9765e-04 - dice_myelin: 0.6024 - val_loss: 0.3323 - val_acc: 0.6678 - val_dice_axon: 9.8252e-05 - val_dice_myelin: 0.7787\n",
      "Epoch 26/1000\n",
      "73/73 [==============================] - 38s 525ms/step - loss: 0.4023 - acc: 0.6008 - dice_axon: 2.7170e-04 - dice_myelin: 0.6690 - val_loss: 0.3345 - val_acc: 0.6656 - val_dice_axon: 1.0222e-04 - val_dice_myelin: 0.7764\n",
      "Epoch 27/1000\n",
      "73/73 [==============================] - 38s 518ms/step - loss: 0.3809 - acc: 0.5940 - dice_axon: 2.4077e-04 - dice_myelin: 0.6325 - val_loss: 0.3445 - val_acc: 0.6555 - val_dice_axon: 1.2500e-04 - val_dice_myelin: 0.7662\n",
      "Epoch 28/1000\n",
      "73/73 [==============================] - 38s 519ms/step - loss: 0.3861 - acc: 0.5871 - dice_axon: 2.3713e-04 - dice_myelin: 0.6236 - val_loss: 0.3584 - val_acc: 0.6417 - val_dice_axon: 1.4477e-04 - val_dice_myelin: 0.7311\n",
      "Epoch 29/1000\n",
      "73/73 [==============================] - 38s 521ms/step - loss: 0.3953 - acc: 0.5757 - dice_axon: 2.3907e-04 - dice_myelin: 0.6012 - val_loss: 0.3469 - val_acc: 0.6532 - val_dice_axon: 9.3230e-05 - val_dice_myelin: 0.7783\n",
      "Epoch 30/1000\n",
      "73/73 [==============================] - 38s 516ms/step - loss: 0.3875 - acc: 0.5840 - dice_axon: 2.1245e-04 - dice_myelin: 0.6138 - val_loss: 0.3345 - val_acc: 0.6656 - val_dice_axon: 1.0432e-04 - val_dice_myelin: 0.7737\n",
      "Epoch 31/1000\n",
      "73/73 [==============================] - 37s 512ms/step - loss: 0.3959 - acc: 0.5745 - dice_axon: 2.1416e-04 - dice_myelin: 0.6236 - val_loss: 0.3418 - val_acc: 0.6582 - val_dice_axon: 7.0702e-05 - val_dice_myelin: 0.7843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000\n",
      "73/73 [==============================] - 37s 513ms/step - loss: 0.3820 - acc: 0.5907 - dice_axon: 1.9833e-04 - dice_myelin: 0.6145 - val_loss: 0.3404 - val_acc: 0.6597 - val_dice_axon: 9.0038e-05 - val_dice_myelin: 0.7859\n",
      "Epoch 33/1000\n",
      "73/73 [==============================] - 39s 529ms/step - loss: 0.3927 - acc: 0.5795 - dice_axon: 1.9541e-04 - dice_myelin: 0.6266 - val_loss: 0.3384 - val_acc: 0.6617 - val_dice_axon: 8.2838e-05 - val_dice_myelin: 0.7705\n",
      "Epoch 34/1000\n",
      "73/73 [==============================] - 38s 518ms/step - loss: 0.3792 - acc: 0.5943 - dice_axon: 1.8379e-04 - dice_myelin: 0.6180 - val_loss: 0.3355 - val_acc: 0.6646 - val_dice_axon: 6.9529e-05 - val_dice_myelin: 0.7835\n",
      "Epoch 35/1000\n",
      "73/73 [==============================] - 38s 518ms/step - loss: 0.3870 - acc: 0.5860 - dice_axon: 1.9036e-04 - dice_myelin: 0.6280 - val_loss: 0.3402 - val_acc: 0.6599 - val_dice_axon: 5.9934e-05 - val_dice_myelin: 0.7717\n",
      "Epoch 36/1000\n",
      "73/73 [==============================] - 37s 505ms/step - loss: 0.3910 - acc: 0.5858 - dice_axon: 1.7558e-04 - dice_myelin: 0.6312 - val_loss: 0.3311 - val_acc: 0.6689 - val_dice_axon: 5.3736e-05 - val_dice_myelin: 0.7820\n",
      "Epoch 37/1000\n",
      "73/73 [==============================] - 39s 535ms/step - loss: 0.3856 - acc: 0.5900 - dice_axon: 1.8248e-04 - dice_myelin: 0.6382 - val_loss: 0.3333 - val_acc: 0.6668 - val_dice_axon: 5.9675e-05 - val_dice_myelin: 0.7773\n",
      "Epoch 38/1000\n",
      "73/73 [==============================] - 38s 518ms/step - loss: 0.3824 - acc: 0.5894 - dice_axon: 1.6091e-04 - dice_myelin: 0.6236 - val_loss: 0.3373 - val_acc: 0.6628 - val_dice_axon: 7.9650e-05 - val_dice_myelin: 0.7998\n",
      "Epoch 39/1000\n",
      "73/73 [==============================] - 37s 512ms/step - loss: 0.3864 - acc: 0.5855 - dice_axon: 1.6153e-04 - dice_myelin: 0.6178 - val_loss: 0.3482 - val_acc: 0.6518 - val_dice_axon: 3.5484e-05 - val_dice_myelin: 0.7421\n",
      "Epoch 40/1000\n",
      "73/73 [==============================] - 39s 536ms/step - loss: 0.3861 - acc: 0.5885 - dice_axon: 1.5605e-04 - dice_myelin: 0.6289 - val_loss: 0.3453 - val_acc: 0.6547 - val_dice_axon: 4.0429e-05 - val_dice_myelin: 0.7453\n",
      "Epoch 41/1000\n",
      "73/73 [==============================] - 39s 534ms/step - loss: 0.3876 - acc: 0.5892 - dice_axon: 1.6628e-04 - dice_myelin: 0.6424 - val_loss: 0.3503 - val_acc: 0.6498 - val_dice_axon: 9.1898e-05 - val_dice_myelin: 0.7963\n",
      "Epoch 42/1000\n",
      "73/73 [==============================] - 38s 519ms/step - loss: 0.3811 - acc: 0.5956 - dice_axon: 1.6135e-04 - dice_myelin: 0.6397 - val_loss: 0.3433 - val_acc: 0.6568 - val_dice_axon: 6.8665e-05 - val_dice_myelin: 0.7856\n",
      "Epoch 43/1000\n",
      "73/73 [==============================] - 38s 520ms/step - loss: 0.3822 - acc: 0.5932 - dice_axon: 1.4117e-04 - dice_myelin: 0.6413 - val_loss: 0.3577 - val_acc: 0.6424 - val_dice_axon: 3.7951e-05 - val_dice_myelin: 0.7706\n",
      "Epoch 44/1000\n",
      "73/73 [==============================] - 39s 533ms/step - loss: 0.3877 - acc: 0.5873 - dice_axon: 1.2406e-04 - dice_myelin: 0.6096 - val_loss: 0.3295 - val_acc: 0.6706 - val_dice_axon: 5.8019e-05 - val_dice_myelin: 0.7821\n",
      "Epoch 45/1000\n",
      "73/73 [==============================] - 37s 502ms/step - loss: 0.3920 - acc: 0.5837 - dice_axon: 1.3088e-04 - dice_myelin: 0.6499 - val_loss: 0.3318 - val_acc: 0.6683 - val_dice_axon: 4.8098e-05 - val_dice_myelin: 0.7838\n",
      "Epoch 46/1000\n",
      "73/73 [==============================] - 37s 500ms/step - loss: 0.3831 - acc: 0.5890 - dice_axon: 1.3176e-04 - dice_myelin: 0.6260 - val_loss: 0.3356 - val_acc: 0.6645 - val_dice_axon: 4.0776e-05 - val_dice_myelin: 0.7953\n",
      "Epoch 47/1000\n",
      "73/73 [==============================] - 38s 521ms/step - loss: 0.3843 - acc: 0.5887 - dice_axon: 1.3387e-04 - dice_myelin: 0.6166 - val_loss: 0.3417 - val_acc: 0.6583 - val_dice_axon: 1.9974e-05 - val_dice_myelin: 0.7762\n",
      "Epoch 48/1000\n",
      "73/73 [==============================] - 37s 504ms/step - loss: 0.3869 - acc: 0.5878 - dice_axon: 1.1778e-04 - dice_myelin: 0.6431 - val_loss: 0.3593 - val_acc: 0.6407 - val_dice_axon: 2.5708e-05 - val_dice_myelin: 0.7288\n",
      "Epoch 49/1000\n",
      "73/73 [==============================] - 37s 501ms/step - loss: 0.3794 - acc: 0.5926 - dice_axon: 1.1203e-04 - dice_myelin: 0.6234 - val_loss: 0.3356 - val_acc: 0.6645 - val_dice_axon: 5.6297e-05 - val_dice_myelin: 0.7680\n",
      "Epoch 50/1000\n",
      "73/73 [==============================] - 38s 519ms/step - loss: 0.3920 - acc: 0.5809 - dice_axon: 1.1930e-04 - dice_myelin: 0.6339 - val_loss: 0.3427 - val_acc: 0.6573 - val_dice_axon: 5.4290e-05 - val_dice_myelin: 0.7812\n",
      "Epoch 51/1000\n",
      "73/73 [==============================] - 37s 504ms/step - loss: 0.3814 - acc: 0.5909 - dice_axon: 1.1729e-04 - dice_myelin: 0.6291 - val_loss: 0.3400 - val_acc: 0.6600 - val_dice_axon: 6.2184e-05 - val_dice_myelin: 0.7826\n",
      "Epoch 52/1000\n",
      "73/73 [==============================] - 37s 507ms/step - loss: 0.3797 - acc: 0.5948 - dice_axon: 1.1403e-04 - dice_myelin: 0.6254 - val_loss: 0.3333 - val_acc: 0.6667 - val_dice_axon: 4.9195e-05 - val_dice_myelin: 0.7859\n",
      "Epoch 53/1000\n",
      "73/73 [==============================] - 38s 525ms/step - loss: 0.3931 - acc: 0.5810 - dice_axon: 1.1701e-04 - dice_myelin: 0.6441 - val_loss: 0.3331 - val_acc: 0.6669 - val_dice_axon: 5.7542e-05 - val_dice_myelin: 0.7893\n",
      "Epoch 54/1000\n",
      "73/73 [==============================] - 38s 525ms/step - loss: 0.3699 - acc: 0.6038 - dice_axon: 9.8568e-05 - dice_myelin: 0.6231 - val_loss: 0.3330 - val_acc: 0.6670 - val_dice_axon: 4.0999e-05 - val_dice_myelin: 0.7949\n",
      "Epoch 55/1000\n",
      "73/73 [==============================] - 38s 517ms/step - loss: 0.3940 - acc: 0.5821 - dice_axon: 1.1781e-04 - dice_myelin: 0.6479 - val_loss: 0.3297 - val_acc: 0.6704 - val_dice_axon: 1.0298e-04 - val_dice_myelin: 0.7849\n",
      "Epoch 56/1000\n",
      "73/73 [==============================] - 36s 492ms/step - loss: 0.3759 - acc: 0.5952 - dice_axon: 1.0157e-04 - dice_myelin: 0.6084 - val_loss: 0.3419 - val_acc: 0.6582 - val_dice_axon: 1.7125e-04 - val_dice_myelin: 0.7532\n",
      "Epoch 57/1000\n",
      "73/73 [==============================] - 37s 510ms/step - loss: 0.3819 - acc: 0.5927 - dice_axon: 1.0839e-04 - dice_myelin: 0.6302 - val_loss: 0.3331 - val_acc: 0.6670 - val_dice_axon: 4.8821e-05 - val_dice_myelin: 0.8057\n",
      "Epoch 58/1000\n",
      "73/73 [==============================] - 36s 495ms/step - loss: 0.3754 - acc: 0.6010 - dice_axon: 1.0227e-04 - dice_myelin: 0.6291 - val_loss: 0.3344 - val_acc: 0.6656 - val_dice_axon: 3.9005e-05 - val_dice_myelin: 0.7901\n",
      "Epoch 59/1000\n",
      "73/73 [==============================] - 40s 544ms/step - loss: 0.3956 - acc: 0.5781 - dice_axon: 1.0341e-04 - dice_myelin: 0.6279 - val_loss: 0.3412 - val_acc: 0.6589 - val_dice_axon: 4.8808e-05 - val_dice_myelin: 0.7608\n",
      "Epoch 60/1000\n",
      "73/73 [==============================] - 38s 518ms/step - loss: 0.3943 - acc: 0.5802 - dice_axon: 9.4712e-05 - dice_myelin: 0.6367 - val_loss: 0.3482 - val_acc: 0.6518 - val_dice_axon: 7.3722e-05 - val_dice_myelin: 0.7987\n",
      "Epoch 61/1000\n",
      "73/73 [==============================] - 38s 515ms/step - loss: 0.3700 - acc: 0.6049 - dice_axon: 9.0558e-05 - dice_myelin: 0.6275 - val_loss: 0.3460 - val_acc: 0.6540 - val_dice_axon: 5.1927e-05 - val_dice_myelin: 0.7764\n",
      "Epoch 62/1000\n",
      "73/73 [==============================] - 37s 505ms/step - loss: 0.3946 - acc: 0.5776 - dice_axon: 9.4332e-05 - dice_myelin: 0.6208 - val_loss: 0.3474 - val_acc: 0.6527 - val_dice_axon: 4.6951e-05 - val_dice_myelin: 0.8033\n",
      "Epoch 63/1000\n",
      "73/73 [==============================] - 40s 545ms/step - loss: 0.3854 - acc: 0.5898 - dice_axon: 9.5868e-05 - dice_myelin: 0.6442 - val_loss: 0.3440 - val_acc: 0.6560 - val_dice_axon: 2.5631e-05 - val_dice_myelin: 0.7353\n",
      "Epoch 64/1000\n",
      "73/73 [==============================] - 38s 524ms/step - loss: 0.3831 - acc: 0.5893 - dice_axon: 9.6882e-05 - dice_myelin: 0.6256 - val_loss: 0.3311 - val_acc: 0.6689 - val_dice_axon: 6.1428e-05 - val_dice_myelin: 0.7829\n",
      "Epoch 65/1000\n",
      "73/73 [==============================] - 37s 512ms/step - loss: 0.3857 - acc: 0.5874 - dice_axon: 8.4229e-05 - dice_myelin: 0.6339 - val_loss: 0.3360 - val_acc: 0.6641 - val_dice_axon: 3.5145e-05 - val_dice_myelin: 0.7965\n",
      "Epoch 66/1000\n",
      "73/73 [==============================] - 38s 517ms/step - loss: 0.3738 - acc: 0.6004 - dice_axon: 8.9856e-05 - dice_myelin: 0.6311 - val_loss: 0.3378 - val_acc: 0.6623 - val_dice_axon: 5.2324e-05 - val_dice_myelin: 0.7828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "73/73 [==============================] - 38s 517ms/step - loss: 0.3734 - acc: 0.5992 - dice_axon: 7.9440e-05 - dice_myelin: 0.6261 - val_loss: 0.3370 - val_acc: 0.6630 - val_dice_axon: 3.2012e-05 - val_dice_myelin: 0.8036\n",
      "Epoch 68/1000\n",
      "73/73 [==============================] - 38s 518ms/step - loss: 0.3971 - acc: 0.5762 - dice_axon: 8.5108e-05 - dice_myelin: 0.6429 - val_loss: 0.3309 - val_acc: 0.6692 - val_dice_axon: 4.6840e-05 - val_dice_myelin: 0.7844\n",
      "Epoch 69/1000\n",
      "73/73 [==============================] - 37s 508ms/step - loss: 0.3802 - acc: 0.5963 - dice_axon: 8.0980e-05 - dice_myelin: 0.6426 - val_loss: 0.3393 - val_acc: 0.6608 - val_dice_axon: 5.0297e-05 - val_dice_myelin: 0.7878\n",
      "Epoch 70/1000\n",
      "73/73 [==============================] - 39s 535ms/step - loss: 0.3763 - acc: 0.5974 - dice_axon: 8.0967e-05 - dice_myelin: 0.6248 - val_loss: 0.3443 - val_acc: 0.6557 - val_dice_axon: 6.3991e-05 - val_dice_myelin: 0.7677\n",
      "Epoch 71/1000\n",
      "73/73 [==============================] - 36s 494ms/step - loss: 0.3806 - acc: 0.5931 - dice_axon: 8.4764e-05 - dice_myelin: 0.6408 - val_loss: 0.3319 - val_acc: 0.6681 - val_dice_axon: 5.5254e-05 - val_dice_myelin: 0.7867\n",
      "Epoch 72/1000\n",
      "73/73 [==============================] - 37s 510ms/step - loss: 0.3806 - acc: 0.5927 - dice_axon: 8.7037e-05 - dice_myelin: 0.6328 - val_loss: 0.3300 - val_acc: 0.6701 - val_dice_axon: 5.6432e-05 - val_dice_myelin: 0.7986\n",
      "Epoch 73/1000\n",
      "73/73 [==============================] - 38s 515ms/step - loss: 0.3847 - acc: 0.6104 - dice_axon: 6.3034e-05 - dice_myelin: 0.6578 - val_loss: 0.3768 - val_acc: 0.6232 - val_dice_axon: 4.1917e-05 - val_dice_myelin: 0.6930\n",
      "Epoch 74/1000\n",
      "73/73 [==============================] - 37s 508ms/step - loss: 0.3818 - acc: 0.5915 - dice_axon: 7.9135e-05 - dice_myelin: 0.6325 - val_loss: 0.3258 - val_acc: 0.6743 - val_dice_axon: 4.6482e-05 - val_dice_myelin: 0.7990\n",
      "Epoch 75/1000\n",
      "73/73 [==============================] - 37s 513ms/step - loss: 0.3863 - acc: 0.5855 - dice_axon: 8.3574e-05 - dice_myelin: 0.6264 - val_loss: 0.3285 - val_acc: 0.6715 - val_dice_axon: 3.1863e-05 - val_dice_myelin: 0.7933\n",
      "Epoch 76/1000\n",
      "73/73 [==============================] - 37s 511ms/step - loss: 0.3824 - acc: 0.5890 - dice_axon: 7.7669e-05 - dice_myelin: 0.6255 - val_loss: 0.3329 - val_acc: 0.6671 - val_dice_axon: 3.2905e-05 - val_dice_myelin: 0.8117\n",
      "Epoch 77/1000\n",
      "73/73 [==============================] - 36s 500ms/step - loss: 0.3855 - acc: 0.5841 - dice_axon: 8.6383e-05 - dice_myelin: 0.6195 - val_loss: 0.3306 - val_acc: 0.6695 - val_dice_axon: 5.5887e-05 - val_dice_myelin: 0.8003\n",
      "Epoch 78/1000\n",
      "73/73 [==============================] - 37s 505ms/step - loss: 0.3821 - acc: 0.5911 - dice_axon: 1.0090e-04 - dice_myelin: 0.6391 - val_loss: 0.3293 - val_acc: 0.6707 - val_dice_axon: 6.4138e-05 - val_dice_myelin: 0.7937\n",
      "Epoch 79/1000\n",
      "73/73 [==============================] - 36s 498ms/step - loss: 0.3776 - acc: 0.5918 - dice_axon: 8.5950e-05 - dice_myelin: 0.6209 - val_loss: 0.3534 - val_acc: 0.6468 - val_dice_axon: 1.5252e-04 - val_dice_myelin: 0.7846\n",
      "Epoch 80/1000\n",
      "73/73 [==============================] - 37s 511ms/step - loss: 0.3914 - acc: 0.5901 - dice_axon: 7.1977e-05 - dice_myelin: 0.6393 - val_loss: 0.3371 - val_acc: 0.6630 - val_dice_axon: 2.9978e-05 - val_dice_myelin: 0.8062\n",
      "Epoch 81/1000\n",
      "73/73 [==============================] - 36s 500ms/step - loss: 0.3763 - acc: 0.5979 - dice_axon: 8.7206e-05 - dice_myelin: 0.6384 - val_loss: 0.3449 - val_acc: 0.6551 - val_dice_axon: 3.4412e-05 - val_dice_myelin: 0.8110\n",
      "Epoch 82/1000\n",
      "73/73 [==============================] - 37s 513ms/step - loss: 0.3769 - acc: 0.5966 - dice_axon: 6.6649e-05 - dice_myelin: 0.6297 - val_loss: 0.3276 - val_acc: 0.6725 - val_dice_axon: 2.1537e-05 - val_dice_myelin: 0.7909\n",
      "Epoch 83/1000\n",
      "73/73 [==============================] - 37s 505ms/step - loss: 0.3873 - acc: 0.5854 - dice_axon: 8.6175e-05 - dice_myelin: 0.6392 - val_loss: 0.3314 - val_acc: 0.6686 - val_dice_axon: 3.1874e-05 - val_dice_myelin: 0.7839\n",
      "Epoch 84/1000\n",
      "73/73 [==============================] - 38s 518ms/step - loss: 0.3789 - acc: 0.5967 - dice_axon: 8.9798e-05 - dice_myelin: 0.6534 - val_loss: 0.3354 - val_acc: 0.6646 - val_dice_axon: 3.4646e-05 - val_dice_myelin: 0.7968\n",
      "Epoch 85/1000\n",
      "73/73 [==============================] - 37s 507ms/step - loss: 0.3670 - acc: 0.6093 - dice_axon: 7.4539e-05 - dice_myelin: 0.6294 - val_loss: 0.3303 - val_acc: 0.6697 - val_dice_axon: 4.1099e-05 - val_dice_myelin: 0.8058\n",
      "Epoch 86/1000\n",
      "73/73 [==============================] - 38s 526ms/step - loss: 0.3887 - acc: 0.5903 - dice_axon: 8.0639e-05 - dice_myelin: 0.6309 - val_loss: 0.3374 - val_acc: 0.6627 - val_dice_axon: 5.5371e-05 - val_dice_myelin: 0.8032\n",
      "Epoch 87/1000\n",
      "73/73 [==============================] - 38s 520ms/step - loss: 0.3875 - acc: 0.5864 - dice_axon: 9.7516e-05 - dice_myelin: 0.6522 - val_loss: 0.3276 - val_acc: 0.6724 - val_dice_axon: 4.6820e-05 - val_dice_myelin: 0.7975\n",
      "Epoch 88/1000\n",
      "73/73 [==============================] - 37s 507ms/step - loss: 0.3702 - acc: 0.6016 - dice_axon: 1.0801e-04 - dice_myelin: 0.6346 - val_loss: 0.3324 - val_acc: 0.6676 - val_dice_axon: 8.0797e-05 - val_dice_myelin: 0.8128\n",
      "Epoch 89/1000\n",
      "73/73 [==============================] - 38s 518ms/step - loss: 0.3844 - acc: 0.5882 - dice_axon: 1.2050e-04 - dice_myelin: 0.6391 - val_loss: 0.3335 - val_acc: 0.6665 - val_dice_axon: 1.0146e-04 - val_dice_myelin: 0.8007\n",
      "Epoch 90/1000\n",
      "73/73 [==============================] - 37s 513ms/step - loss: 0.3736 - acc: 0.6009 - dice_axon: 1.2168e-04 - dice_myelin: 0.6451 - val_loss: 0.3369 - val_acc: 0.6631 - val_dice_axon: 3.9064e-05 - val_dice_myelin: 0.7706\n",
      "Epoch 91/1000\n",
      "73/73 [==============================] - 38s 517ms/step - loss: 0.3791 - acc: 0.5965 - dice_axon: 4.8197e-05 - dice_myelin: 0.6326 - val_loss: 0.3337 - val_acc: 0.6663 - val_dice_axon: 2.5335e-05 - val_dice_myelin: 0.7884\n",
      "Epoch 92/1000\n",
      "73/73 [==============================] - 38s 516ms/step - loss: 0.3863 - acc: 0.5868 - dice_axon: 6.9641e-05 - dice_myelin: 0.6481 - val_loss: 0.3284 - val_acc: 0.6716 - val_dice_axon: 3.7021e-05 - val_dice_myelin: 0.8106\n",
      "Epoch 93/1000\n",
      "73/73 [==============================] - 38s 517ms/step - loss: 0.3726 - acc: 0.5994 - dice_axon: 8.4901e-05 - dice_myelin: 0.6298 - val_loss: 0.3231 - val_acc: 0.6769 - val_dice_axon: 4.7017e-05 - val_dice_myelin: 0.8097\n",
      "Epoch 94/1000\n",
      "73/73 [==============================] - 37s 508ms/step - loss: 0.3874 - acc: 0.5829 - dice_axon: 1.0490e-04 - dice_myelin: 0.6398 - val_loss: 0.3232 - val_acc: 0.6768 - val_dice_axon: 9.2315e-05 - val_dice_myelin: 0.8016\n",
      "Epoch 95/1000\n",
      "73/73 [==============================] - 37s 511ms/step - loss: 0.3819 - acc: 0.5911 - dice_axon: 1.3362e-04 - dice_myelin: 0.6481 - val_loss: 0.3291 - val_acc: 0.6709 - val_dice_axon: 4.4936e-05 - val_dice_myelin: 0.8188\n",
      "Epoch 96/1000\n",
      "73/73 [==============================] - 38s 519ms/step - loss: 0.3661 - acc: 0.6043 - dice_axon: 1.3449e-04 - dice_myelin: 0.6255 - val_loss: 0.3297 - val_acc: 0.6703 - val_dice_axon: 5.2238e-05 - val_dice_myelin: 0.8031\n",
      "Epoch 97/1000\n",
      "73/73 [==============================] - 40s 542ms/step - loss: 0.3840 - acc: 0.5906 - dice_axon: 1.4671e-04 - dice_myelin: 0.6557 - val_loss: 0.3257 - val_acc: 0.6744 - val_dice_axon: 7.4337e-05 - val_dice_myelin: 0.8071\n",
      "Epoch 98/1000\n",
      "73/73 [==============================] - 37s 510ms/step - loss: 0.3732 - acc: 0.6001 - dice_axon: 1.7861e-04 - dice_myelin: 0.6487 - val_loss: 0.3423 - val_acc: 0.6577 - val_dice_axon: 4.8969e-05 - val_dice_myelin: 0.8108\n",
      "Epoch 99/1000\n",
      "73/73 [==============================] - 37s 508ms/step - loss: 0.3824 - acc: 0.5878 - dice_axon: 1.7900e-04 - dice_myelin: 0.6333 - val_loss: 0.3335 - val_acc: 0.6666 - val_dice_axon: 1.4296e-04 - val_dice_myelin: 0.8185\n",
      "Epoch 100/1000\n",
      "73/73 [==============================] - 38s 519ms/step - loss: 0.3705 - acc: 0.6031 - dice_axon: 1.5468e-04 - dice_myelin: 0.6320 - val_loss: 0.3412 - val_acc: 0.6588 - val_dice_axon: 4.4328e-05 - val_dice_myelin: 0.8225\n",
      "Epoch 101/1000\n",
      "73/73 [==============================] - 37s 509ms/step - loss: 0.3872 - acc: 0.5954 - dice_axon: 1.8413e-04 - dice_myelin: 0.6784 - val_loss: 0.3206 - val_acc: 0.6794 - val_dice_axon: 9.6277e-05 - val_dice_myelin: 0.8126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/1000\n",
      "73/73 [==============================] - 38s 517ms/step - loss: 0.3631 - acc: 0.6170 - dice_axon: 1.8975e-04 - dice_myelin: 0.6484 - val_loss: 0.3220 - val_acc: 0.6781 - val_dice_axon: 9.0528e-05 - val_dice_myelin: 0.8170\n",
      "Epoch 103/1000\n",
      "73/73 [==============================] - 38s 519ms/step - loss: 0.3857 - acc: 0.6027 - dice_axon: 1.2469e-04 - dice_myelin: 0.6597 - val_loss: 0.3264 - val_acc: 0.6736 - val_dice_axon: 9.4615e-05 - val_dice_myelin: 0.8247\n",
      "Epoch 104/1000\n",
      "73/73 [==============================] - 37s 507ms/step - loss: 0.3636 - acc: 0.6092 - dice_axon: 1.7121e-04 - dice_myelin: 0.6350 - val_loss: 0.3262 - val_acc: 0.6738 - val_dice_axon: 1.2921e-04 - val_dice_myelin: 0.8217\n",
      "Epoch 105/1000\n",
      "73/73 [==============================] - 36s 499ms/step - loss: 0.3866 - acc: 0.5940 - dice_axon: 2.5662e-04 - dice_myelin: 0.6624 - val_loss: 0.3297 - val_acc: 0.6703 - val_dice_axon: 1.3701e-04 - val_dice_myelin: 0.8288\n",
      "Epoch 106/1000\n",
      "73/73 [==============================] - 38s 518ms/step - loss: 0.3695 - acc: 0.6150 - dice_axon: 3.0854e-04 - dice_myelin: 0.6643 - val_loss: 0.3234 - val_acc: 0.6766 - val_dice_axon: 3.0633e-04 - val_dice_myelin: 0.8135\n",
      "Epoch 107/1000\n",
      "73/73 [==============================] - 37s 510ms/step - loss: 0.3725 - acc: 0.6022 - dice_axon: 3.5398e-04 - dice_myelin: 0.6486 - val_loss: 0.3376 - val_acc: 0.6624 - val_dice_axon: 1.7126e-04 - val_dice_myelin: 0.7976\n",
      "Epoch 108/1000\n",
      "73/73 [==============================] - 38s 517ms/step - loss: 0.3745 - acc: 0.5998 - dice_axon: 4.6051e-04 - dice_myelin: 0.6565 - val_loss: 0.3288 - val_acc: 0.6712 - val_dice_axon: 3.5425e-04 - val_dice_myelin: 0.8131\n",
      "Epoch 109/1000\n",
      "73/73 [==============================] - 38s 523ms/step - loss: 0.3723 - acc: 0.6006 - dice_axon: 5.0871e-04 - dice_myelin: 0.6507 - val_loss: 0.3379 - val_acc: 0.6622 - val_dice_axon: 3.2607e-04 - val_dice_myelin: 0.7612\n",
      "Epoch 110/1000\n",
      "73/73 [==============================] - 38s 525ms/step - loss: 0.3708 - acc: 0.6086 - dice_axon: 5.2663e-04 - dice_myelin: 0.6610 - val_loss: 0.3222 - val_acc: 0.6778 - val_dice_axon: 7.9742e-04 - val_dice_myelin: 0.8220\n",
      "Epoch 111/1000\n",
      "73/73 [==============================] - 38s 515ms/step - loss: 0.3775 - acc: 0.6081 - dice_axon: 9.2459e-04 - dice_myelin: 0.6655 - val_loss: 0.3314 - val_acc: 0.6686 - val_dice_axon: 4.9762e-04 - val_dice_myelin: 0.7966\n",
      "Epoch 112/1000\n",
      "73/73 [==============================] - 38s 519ms/step - loss: 0.3624 - acc: 0.6147 - dice_axon: 0.0029 - dice_myelin: 0.6503 - val_loss: 0.3181 - val_acc: 0.6819 - val_dice_axon: 0.0064 - val_dice_myelin: 0.8205\n",
      "Epoch 113/1000\n",
      "73/73 [==============================] - 38s 520ms/step - loss: 0.3824 - acc: 0.5898 - dice_axon: 0.0458 - dice_myelin: 0.6503 - val_loss: 0.3145 - val_acc: 0.6856 - val_dice_axon: 0.1371 - val_dice_myelin: 0.8020\n",
      "Epoch 114/1000\n",
      "73/73 [==============================] - 39s 530ms/step - loss: 0.3057 - acc: 0.6735 - dice_axon: 0.4742 - dice_myelin: 0.6112 - val_loss: 0.1595 - val_acc: 0.8406 - val_dice_axon: 0.7764 - val_dice_myelin: 0.8040\n",
      "Epoch 115/1000\n",
      "73/73 [==============================] - 37s 512ms/step - loss: 0.1962 - acc: 0.8123 - dice_axon: 0.7946 - dice_myelin: 0.7286 - val_loss: 0.1200 - val_acc: 0.8800 - val_dice_axon: 0.8360 - val_dice_myelin: 0.8159\n",
      "Epoch 116/1000\n",
      "73/73 [==============================] - 40s 541ms/step - loss: 0.1809 - acc: 0.8109 - dice_axon: 0.7838 - dice_myelin: 0.6861 - val_loss: 0.1063 - val_acc: 0.8938 - val_dice_axon: 0.8617 - val_dice_myelin: 0.8067\n",
      "Epoch 117/1000\n",
      "73/73 [==============================] - 38s 526ms/step - loss: 0.1719 - acc: 0.8204 - dice_axon: 0.8140 - dice_myelin: 0.7232 - val_loss: 0.1251 - val_acc: 0.8749 - val_dice_axon: 0.8491 - val_dice_myelin: 0.8084\n",
      "Epoch 118/1000\n",
      "73/73 [==============================] - 37s 503ms/step - loss: 0.1672 - acc: 0.8260 - dice_axon: 0.7656 - dice_myelin: 0.7235 - val_loss: 0.1002 - val_acc: 0.8998 - val_dice_axon: 0.8743 - val_dice_myelin: 0.8262\n",
      "Epoch 119/1000\n",
      "73/73 [==============================] - 38s 522ms/step - loss: 0.1490 - acc: 0.8477 - dice_axon: 0.8445 - dice_myelin: 0.7396 - val_loss: 0.0966 - val_acc: 0.9034 - val_dice_axon: 0.8881 - val_dice_myelin: 0.8319\n",
      "Epoch 120/1000\n",
      "73/73 [==============================] - 37s 510ms/step - loss: 0.1526 - acc: 0.8368 - dice_axon: 0.8153 - dice_myelin: 0.7152 - val_loss: 0.0929 - val_acc: 0.9072 - val_dice_axon: 0.8865 - val_dice_myelin: 0.8218\n",
      "Epoch 121/1000\n",
      "73/73 [==============================] - 34s 468ms/step - loss: 0.1503 - acc: 0.8203 - dice_axon: 0.8101 - dice_myelin: 0.7009 - val_loss: 0.1040 - val_acc: 0.8961 - val_dice_axon: 0.8638 - val_dice_myelin: 0.8190\n",
      "Epoch 122/1000\n",
      "73/73 [==============================] - 37s 504ms/step - loss: 0.1491 - acc: 0.8289 - dice_axon: 0.8073 - dice_myelin: 0.7277 - val_loss: 0.1025 - val_acc: 0.8976 - val_dice_axon: 0.8781 - val_dice_myelin: 0.8125\n",
      "Epoch 123/1000\n",
      "73/73 [==============================] - 37s 510ms/step - loss: 0.1354 - acc: 0.8436 - dice_axon: 0.8338 - dice_myelin: 0.7324 - val_loss: 0.0866 - val_acc: 0.9135 - val_dice_axon: 0.8909 - val_dice_myelin: 0.8380\n",
      "Epoch 124/1000\n",
      "73/73 [==============================] - 36s 491ms/step - loss: 0.1488 - acc: 0.8339 - dice_axon: 0.8135 - dice_myelin: 0.7283 - val_loss: 0.0985 - val_acc: 0.9016 - val_dice_axon: 0.8802 - val_dice_myelin: 0.8116\n",
      "Epoch 125/1000\n",
      "73/73 [==============================] - 38s 515ms/step - loss: 0.1384 - acc: 0.8310 - dice_axon: 0.8302 - dice_myelin: 0.7013 - val_loss: 0.1035 - val_acc: 0.8965 - val_dice_axon: 0.8638 - val_dice_myelin: 0.8102\n",
      "Epoch 126/1000\n",
      "73/73 [==============================] - 38s 516ms/step - loss: 0.1294 - acc: 0.8575 - dice_axon: 0.8534 - dice_myelin: 0.7293 - val_loss: 0.0879 - val_acc: 0.9121 - val_dice_axon: 0.8910 - val_dice_myelin: 0.8329\n",
      "Epoch 127/1000\n",
      "73/73 [==============================] - 37s 510ms/step - loss: 0.1305 - acc: 0.8578 - dice_axon: 0.8503 - dice_myelin: 0.7331 - val_loss: 0.0872 - val_acc: 0.9128 - val_dice_axon: 0.8904 - val_dice_myelin: 0.8366\n",
      "Epoch 128/1000\n",
      "73/73 [==============================] - 38s 519ms/step - loss: 0.1395 - acc: 0.8343 - dice_axon: 0.8537 - dice_myelin: 0.6862 - val_loss: 0.1079 - val_acc: 0.8921 - val_dice_axon: 0.8746 - val_dice_myelin: 0.7908\n",
      "Epoch 129/1000\n",
      "73/73 [==============================] - 37s 504ms/step - loss: 0.1360 - acc: 0.8485 - dice_axon: 0.8651 - dice_myelin: 0.6971 - val_loss: 0.1352 - val_acc: 0.8648 - val_dice_axon: 0.8347 - val_dice_myelin: 0.7484\n",
      "Epoch 130/1000\n",
      "73/73 [==============================] - 38s 522ms/step - loss: 0.1413 - acc: 0.8282 - dice_axon: 0.8472 - dice_myelin: 0.7007 - val_loss: 0.0850 - val_acc: 0.9150 - val_dice_axon: 0.8931 - val_dice_myelin: 0.8351\n",
      "Epoch 131/1000\n",
      "73/73 [==============================] - 37s 500ms/step - loss: 0.1313 - acc: 0.8449 - dice_axon: 0.8364 - dice_myelin: 0.6995 - val_loss: 0.0858 - val_acc: 0.9142 - val_dice_axon: 0.8875 - val_dice_myelin: 0.8285\n",
      "Epoch 132/1000\n",
      "73/73 [==============================] - 38s 517ms/step - loss: 0.1316 - acc: 0.8559 - dice_axon: 0.8580 - dice_myelin: 0.7574 - val_loss: 0.0910 - val_acc: 0.9090 - val_dice_axon: 0.8790 - val_dice_myelin: 0.8275\n",
      "Epoch 133/1000\n",
      "73/73 [==============================] - 37s 505ms/step - loss: 0.1269 - acc: 0.8587 - dice_axon: 0.8473 - dice_myelin: 0.7342 - val_loss: 0.0801 - val_acc: 0.9199 - val_dice_axon: 0.9011 - val_dice_myelin: 0.8487\n",
      "Epoch 134/1000\n",
      "73/73 [==============================] - 35s 486ms/step - loss: 0.1222 - acc: 0.8550 - dice_axon: 0.8495 - dice_myelin: 0.7274 - val_loss: 0.0891 - val_acc: 0.9110 - val_dice_axon: 0.8927 - val_dice_myelin: 0.8248\n",
      "Epoch 135/1000\n",
      "73/73 [==============================] - 38s 521ms/step - loss: 0.1221 - acc: 0.8632 - dice_axon: 0.8840 - dice_myelin: 0.7292 - val_loss: 0.0706 - val_acc: 0.9294 - val_dice_axon: 0.9119 - val_dice_myelin: 0.8427\n",
      "Epoch 136/1000\n",
      "73/73 [==============================] - 35s 473ms/step - loss: 0.1275 - acc: 0.8587 - dice_axon: 0.8567 - dice_myelin: 0.7223 - val_loss: 0.1452 - val_acc: 0.8549 - val_dice_axon: 0.7860 - val_dice_myelin: 0.7928\n",
      "Epoch 137/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 36s 500ms/step - loss: 0.1198 - acc: 0.8751 - dice_axon: 0.8737 - dice_myelin: 0.7469 - val_loss: 0.0834 - val_acc: 0.9167 - val_dice_axon: 0.8978 - val_dice_myelin: 0.8413\n",
      "Epoch 138/1000\n",
      "72/73 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.8811 - dice_axon: 0.8904 - dice_myelin: 0.7553"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25836/1586317341.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Note: For multi-OS compatibility of this notebook, paths were defined as Path objects from the pathlib module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# They need to be converted into strings prior to be given as arguments to train_model(), as some old-style string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/bzuchero/axondeepseg/AxonDeepSeg/train_network.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(path_trainingset, path_model, config, path_model_init, save_trainable, gpu, debug_mode, gpu_per)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_acc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m/home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/bzuchero/miniconda/envs/ads_venv/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# reset the tensorflow graph for new testing\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train_model(str(path_training), str(path_model), config)\n",
    "# Note: For multi-OS compatibility of this notebook, paths were defined as Path objects from the pathlib module.\n",
    "# They need to be converted into strings prior to be given as arguments to train_model(), as some old-style string\n",
    "# concatenation (e.g. \"+\") are still used in it.\n",
    "# In your own application, simply defining paths with correct syntax for your OS as strings instead of Path\n",
    "# objects would be sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Monitor the training with Tensorboard\n",
    "\n",
    "[TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard) can be used to monitor the training procedure (loss and accuracy graphs, gradients, activations, identify bugs, etc.). To run TensorBoard, activate ADS virtual environment and run:\n",
    "```\n",
    "tensorboard --logdir PATH_MODEL --port 6006\n",
    "```\n",
    "where `PATH_MODEL` corresponds to this notebook's `path_model` variable (folder where model is being trained), and `port` is the port number where the TensorBoard local web server will be sent to (e.g., port 6006). Once the command is run, open a web browser with the address:\n",
    "```\n",
    "http://localhost:6006/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. Resume training from checkpoint\n",
    "\n",
    "To resume training from a checkpoint, change the \"checkpoint\" parameter in \"config\" from None to \"loss\" or \"accuracy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/groups/bzuchero/axondeepseg/notebooks/training/Train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29089/3630749251.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../models/Path_of_the_model\"\u001b[0m \u001b[0;31m# Path of the model where the checkpoint is saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/groups/bzuchero/axondeepseg/AxonDeepSeg/train_network.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(path_trainingset, path_model, config, path_model_init, save_trainable, gpu, debug_mode, gpu_per)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# List of Training Ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mno_train_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_training_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mtrain_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_train_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/groups/bzuchero/axondeepseg/notebooks/training/Train'"
     ]
    }
   ],
   "source": [
    "path_model = \"../models/Path_of_the_model\" # Path of the model where the checkpoint is saved\n",
    "\n",
    "train_model(str(path_training), str(path_model), config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test the trained model\n",
    "#### 2.1. Set the path of the test image to be segmented with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the lines below to use your image\n",
    "path_img = Path(\"../AxonDeepSeg/models/default_TEM_model/data_test\")\n",
    "file_img = \"image.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Launch the image segmentation\n",
    "\n",
    "The target resolution of the current version of the models are 0.1 for the **'default_SEM_model'** and **'OM_model' (model_seg_pns_bf)**, and 0.01 for the **'default_TEM_model'**. In this case, our test sample is a TEM brain sample of the mouse, so we set resampled_resolutions to 0.01.\n",
    "\n",
    "For your own trained model, use a resampled_resolutions corresponding to the general_pixel_size that was set in the 01-guide_dataset_building notebook in section 1.1. \"Define the parameters of the patch extraction\" when you created the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want to test the segmentation with a pre-trained default model, uncomment the line below.\n",
    "#path_model = Path(\"../AxonDeepSeg/models/default_TEM_model\")\n",
    "\n",
    "# reset the tensorflow graph for new testing\n",
    "tf.reset_default_graph()\n",
    "prediction = axon_segmentation(path_img, file_img, path_model, config_network, resampled_resolutions=0.01, verbosity_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Display the resulted segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_img_seg = Path(file_img).stem + str(axonmyelin_suffix)  # axon+myelin segmentation\n",
    "\n",
    "img_seg = ads.imread(path_img / file_img_seg)\n",
    "img = ads.imread(path_img / file_img)\n",
    "# Note: The arguments of the two function calls above use the pathlib syntax for path concatenation.\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(13,10))\n",
    "ax1, ax2 = axes[0], axes[1]\n",
    "ax1.set_title('Original image')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Prediction with the trained model')\n",
    "ax2.imshow(img_seg,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
